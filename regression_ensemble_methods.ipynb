{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from utils import *\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'passenger_count', 'trip_distance', 'RatecodeID',\n",
       "       'store_and_fwd_flag', 'payment_type', 'fare_amount', 'extra', 'mta_tax',\n",
       "       'tolls_amount', 'improvement_surcharge', 'congestion_surcharge',\n",
       "       'Airport_fee', 'is_rush_hour', 'duration', 'PU_borough', 'DO_borough'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 17) (100000,)\n",
      "(72250, 17) (72250,)\n",
      "(15000, 17) (15000,)\n",
      "(12750, 17) (12750,)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet(\"data/nyc-taxis-tips/train_preprocessed_no_hot.parquet\")\n",
    "X = df_train.drop(\"tip_amount\", axis=1)\n",
    "Y = df_train['tip_amount']\n",
    "\n",
    "columns_to_norm = [\n",
    "    'passenger_count',\n",
    "    'trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tolls_amount',\n",
    "    'improvement_surcharge', 'congestion_surcharge', 'Airport_fee','duration'\n",
    "]\n",
    "categorical_cols = [\n",
    "    \"VendorID\", \"RatecodeID\", \"store_and_fwd_flag\", \"payment_type\", \"PU_borough\", \"DO_borough\"\n",
    "]\n",
    "cols_to_exclude = [\n",
    "    'PU_location_lat', 'PU_location_lon', 'DO_location_lat',\n",
    "    'DO_location_lon', 'PU_loc', 'DO_loc',\n",
    "]\n",
    "X = X.drop(cols_to_exclude, axis=1)\n",
    "X[categorical_cols] = X[categorical_cols].astype('category')\n",
    "display(X.columns)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "X_train[columns_to_norm] = scaler.fit_transform(X_train[columns_to_norm])\n",
    "X_val[columns_to_norm] = scaler.transform(X_val[columns_to_norm])\n",
    "X_test[columns_to_norm] = scaler.transform(X_test[columns_to_norm])\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 72250, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.424159\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l1: 1.38789\tvalid_0's l2: 5.45149\n",
      "Starting predicting...\n",
      "The RMSE of prediction is: 2.334842475988417\n",
      "Feature importances: [9, 6, 37, 40, 0, 40, 272, 52, 4, 64, 0, 11, 4, 0, 52, 0, 9]\n",
      "Starting training with custom eval function...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 72250, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.424159\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 5.45149\tvalid_0's RMSLE: 0.521298\n",
      "Starting training with multiple custom eval functions...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 72250, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.424159\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 5.45149\tvalid_0's RMSLE: 0.521298\tvalid_0's RAE: 0.577602\n",
      "Starting predicting...\n",
      "The RMSLE of prediction is: 0.5212978570041317\n",
      "The RAE of prediction is: 0.5776017152762576\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002850 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 48166, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.438554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.427374\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 854\n",
      "[LightGBM] [Info] Number of data points in the train set: 48167, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.406549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 72250, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.424159\n",
      "Best parameters found by grid search are: {'n_estimators': 50, 'num_leaves': 10}\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training...\")\n",
    "# train\n",
    "gbm = lgb.LGBMRegressor(num_leaves=31, learning_rate=0.05, n_estimators=20)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=\"l1\", callbacks=[lgb.early_stopping(5)])\n",
    "\n",
    "print(\"Starting predicting...\")\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "# eval\n",
    "rmse_test = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f\"The RMSE of prediction is: {rmse_test}\")\n",
    "\n",
    "# feature importances\n",
    "print(f\"Feature importances: {list(gbm.feature_importances_)}\")\n",
    "\n",
    "\n",
    "# self-defined eval metric\n",
    "# f(y_true: array, y_pred: array) -> name: str, eval_result: float, is_higher_better: bool\n",
    "# Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return \"RMSLE\", np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False\n",
    "\n",
    "\n",
    "print(\"Starting training with custom eval function...\")\n",
    "# train\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=rmsle, callbacks=[lgb.early_stopping(5)])\n",
    "\n",
    "\n",
    "# another self-defined eval metric\n",
    "# f(y_true: array, y_pred: array) -> name: str, eval_result: float, is_higher_better: bool\n",
    "# Relative Absolute Error (RAE)\n",
    "def rae(y_true, y_pred):\n",
    "    return \"RAE\", np.sum(np.abs(y_pred - y_true)) / np.sum(np.abs(np.mean(y_true) - y_true)), False\n",
    "\n",
    "\n",
    "print(\"Starting training with multiple custom eval functions...\")\n",
    "# train\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=[rmsle, rae], callbacks=[lgb.early_stopping(5)])\n",
    "\n",
    "print(\"Starting predicting...\")\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "# eval\n",
    "rmsle_test = rmsle(y_test, y_pred)[1]\n",
    "rae_test = rae(y_test, y_pred)[1]\n",
    "print(f\"The RMSLE of prediction is: {rmsle_test}\")\n",
    "print(f\"The RAE of prediction is: {rae_test}\")\n",
    "\n",
    "# other scikit-learn modules\n",
    "estimator = lgb.LGBMRegressor(num_leaves=31)\n",
    "\n",
    "param_grid = {\"n_estimators\": [35, 40, 50, 70, 100], \"num_leaves\": [5, 10, 15, 20, 31, 45]}\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid, cv=3)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters found by grid search are: {gbm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 72250, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 3.424159\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's l1: 1.01776\tvalid_0's l2: 4.16857\n",
      "The RMSLE of prediction is: 0.39422214536374506\n",
      "The RAE of prediction is: 0.4235607546255953\n"
     ]
    }
   ],
   "source": [
    "gbm = lgb.LGBMRegressor(num_leaves=10, learning_rate=0.1, n_estimators=50)\n",
    "gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)], eval_metric=\"l1\", callbacks=[lgb.early_stopping(5)])\n",
    "\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "# eval\n",
    "rmsle_test = rmsle(y_test, y_pred)[1]\n",
    "rae_test = rae(y_test, y_pred)[1]\n",
    "print(f\"The RMSLE of prediction is: {rmsle_test}\")\n",
    "print(f\"The RAE of prediction is: {rae_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.041706596879121\n",
      "Coefficient de dtermination (R2 Score): 0.7061151554054528\n"
     ]
    }
   ],
   "source": [
    "# Calcul du Mean Squared Error (MSE) et du R2 Score\n",
    "mse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Affichage des rsultats\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Coefficient de dtermination (R2 Score):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_ID</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.076270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.685867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.038594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.076270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.075244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.892487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>4.211918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.090765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>3.112959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9.692842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>6.111723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2.318713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3.931782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2.617242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3.071618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_ID  tip_amount\n",
       "0        0    2.076270\n",
       "1        1    2.685867\n",
       "2        2    0.038594\n",
       "3        3    2.076270\n",
       "4        4    0.075244\n",
       "5        5    6.892487\n",
       "6        6    4.211918\n",
       "7        7    0.090765\n",
       "8        8    3.112959\n",
       "9        9    9.692842\n",
       "10      10    6.111723\n",
       "11      11    2.318713\n",
       "12      12    3.931782\n",
       "13      13    2.617242\n",
       "14      14    3.071618"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13982\n"
     ]
    }
   ],
   "source": [
    "# test data for Kaggle submission\n",
    "test = pd.read_parquet(\"data/nyc-taxis-tips/test_preprocessed_no_hot.parquet\")\n",
    "\n",
    "# test.drop(columns=[\"RatecodeID_6.0\"], inplace=True)\n",
    "test[categorical_cols] = test[categorical_cols].astype('category')\n",
    "\n",
    "X_sub = test.drop(cols_to_exclude, axis=1)\n",
    "X_sub[columns_to_norm] = scaler.transform(X_sub[columns_to_norm])\n",
    "\n",
    "#predictions = model_ridge_CV.predict(X_sub)\n",
    "predictions = gbm.predict(X_sub)\n",
    "\n",
    "df_pred = pd.DataFrame(predictions, columns=[\"tip_amount\"]).reset_index().rename(columns={\"index\": \"row_ID\"})\n",
    "display(df_pred.head(15))\n",
    "print(sum(df_pred[\"tip_amount\"]<0))\n",
    "df_pred.loc[df_pred.tip_amount < 0, \"tip_amount\"] = 0\n",
    "#df_pred.to_parquet(\"submission/nyc-taxis-tips/regression_sub_1bis.parquet\", index=False)\n",
    "df_pred.to_parquet(\"submission/nyc-taxis-tips/boosting_sub_1.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax',\n",
       "       'tolls_amount', 'improvement_surcharge', 'congestion_surcharge',\n",
       "       'Airport_fee', 'PU_location_lat', 'PU_location_lon', 'DO_location_lat',\n",
       "       'DO_location_lon', 'is_rush_hour', 'duration', 'PU_loc', 'DO_loc',\n",
       "       'VendorID_1', 'VendorID_2', 'RatecodeID_1.0', 'RatecodeID_2.0',\n",
       "       'RatecodeID_3.0', 'RatecodeID_4.0', 'RatecodeID_5.0', 'RatecodeID_99.0',\n",
       "       'store_and_fwd_flag_N', 'store_and_fwd_flag_Y', 'payment_type_1',\n",
       "       'payment_type_2', 'payment_type_3', 'payment_type_4', 'PU_borough_7',\n",
       "       'PU_borough_1', 'PU_borough_3', 'PU_borough_4', 'PU_borough_2',\n",
       "       'PU_borough_6', 'PU_borough_5', 'DO_borough_7', 'DO_borough_1',\n",
       "       'DO_borough_3', 'DO_borough_4', 'DO_borough_2', 'DO_borough_6',\n",
       "       'DO_borough_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3., 99.,  5.,  4.,  6.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"RatecodeID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0, 5.0, 99.0, 4.0]\n",
       "Categories (6, float64): [1.0, 2.0, 3.0, 4.0, 5.0, 99.0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"RatecodeID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
